import io
from typing import Dict

import altair as alt
import pandas as pd
import plotly.express as px
import streamlit as st

from utils import (
    aggregate_sentiment,
    analyze_text_df,
    company_summary,
    compute_stock_indicators,
    parse_uploaded_files,
)

st.set_page_config(page_title="Investment Insights", layout="wide")

st.title("Multi-Company Investment Insight App")

# ---------- Scrape Data Section ----------
st.subheader("Scrape Data")
with st.form("scrape_form"):
    tickers_input = st.text_input(
        "Ticker symbol(s) (comma separated)", help="Up to 3 companies"
    )
    days_input = st.number_input(
        "Days of historical prices",
        min_value=1,
        max_value=3650,
        value=90,
    )
    scrape_button = st.form_submit_button("Scrape")

if scrape_button:
    tickers = [t.strip().upper() for t in tickers_input.split(",") if t.strip()]
    if len(tickers) > 3:
        st.error("Please enter no more than 3 tickers.")
    else:
        from scrape_data import main as scrape_main

        for tkr in tickers:
            with st.spinner(f"Scraping data for {tkr}..."):
                try:
                    scrape_main(tkr, int(days_input))
                    st.success(f"Scraped data for {tkr}. Files saved to current directory.")
                except Exception as e:  # pragma: no cover - manual operation
                    st.error(f"Failed to scrape data for {tkr}: {e}")

uploaded = st.file_uploader(
    "Upload JSON files (max 3 companies)",
    accept_multiple_files=True,
    type="json",
)

if uploaded:
    companies = parse_uploaded_files(uploaded)

    summaries = []
    tabs = st.tabs(list(companies.keys()))
    for (company, data), tab in zip(companies.items(), tabs):
        with tab:
            st.header(company)
            if "stock" in data:
                data["stock"] = compute_stock_indicators(data["stock"])
                fig = px.line(
                    data["stock"],
                    x="date",
                    y=["close", "ma20", "ma50", "ma200"],
                    title=f"{company} Price & MAs",
                )
                st.plotly_chart(fig, use_container_width=True)
                rsi_chart = alt.Chart(data["stock"]).mark_line().encode(
                    x="date:T", y="rsi:Q"
                ).properties(title="RSI")
                st.altair_chart(rsi_chart, use_container_width=True)
                csv = data["stock"].to_csv(index=False).encode("utf-8")
                st.download_button(
                    "Download Stock Data", data=csv, file_name=f"{company}_stock.csv"
                )
            if "news" in data:
                data["news"] = analyze_text_df(data["news"])
                trend = aggregate_sentiment(data["news"])
                if not trend.empty and "date" in trend.columns:
                    fig = px.line(trend, x="date", y="sentiment", title="News Sentiment")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.write("News sentiment trend unavailable: no dates provided.")
            if "filings" in data:
                data["filings"] = analyze_text_df(data["filings"])
                word_freq = pd.DataFrame(data["filings"]["keywords"].tolist()).sum()
                word_chart = alt.Chart(
                    word_freq.reset_index().rename({"index": "keyword", 0: "count"}, axis=1)
                ).mark_bar().encode(x="keyword", y="count")
                st.altair_chart(word_chart, use_container_width=True)
            summaries.append(company_summary(company, data))

    if summaries:
        summary_df = pd.concat(summaries, ignore_index=True)
        st.subheader("Company Comparison")
        st.dataframe(summary_df)
        csv = summary_df.to_csv(index=False).encode("utf-8")
        st.download_button("Download Summary", data=csv, file_name="summary.csv")
else:
    st.info(
        "Use the form above to scrape new data or upload existing JSON files "
        "generated by `scrape_data.py`."
    )
